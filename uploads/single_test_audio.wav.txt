in those situations. Also working on a GPU and when you try to run these algorithms make sure that like when you actually drive the algorithm make sure that your runtime I'll show you how to set it. Make sure that you are like you can one second. You can go to runtime and then click on change runtime type and right now it's in GPU for me. You can put none for it to work in the CPU mode. So during the time when you're trying to you know, write the algorithm itself, maybe you can try. CPU in that during those times and then final because when if you use GPU for a long time longer duration because it's a free version of collab GPU when units will be over and then you have to wait for longer duration for your training if it's if it runs on CPU. So this is how you can change from GPU to CPU. And in case you want to check whether current. If if GPU if there is an available GPU or not, this is how you can check if you do torch.cuda.e is available. It will say because yeah, since my I'm running in on a GPU machine like my runtime is still set to GPU. I will be able to see this. We have a GPU if it had been in the CPU mode. We would have got sorry CPU only so that's one thing. Yeah, this I think I explained this already how to change to GPU runtime. And then yeah, and another thing is the tensor can be shifted between GPU tensor. So I tend to like a tensor also needs to be associated with the device type. Okay, attention needs to know whether it's a CPU tensor or a GPU tensor because since the GPU makes everything faster the type of you know calculations with a tensor goes to the type of workflow for the particular tensor also changes to make the computations faster, right? So the tensor also has its own device type. And this is how you can change the device type. So a equal to a.cuda makes it like you are manually moving it through code you are trying to move the tensor to you are trying to make the tensor to a GPU version and you do a.cpu is going to be a CPU tensor, right? Yeah, so like cuda is like cuda is the Nvidia's name. So like is generally associated with the GPU. So if you see cuda it's a GPU, CPU is normally CPU. And yeah, this is just seeing what the device it is because I'm using cuda. I'm using GPU. You will see that it's cuda. And another main important thing is that if you're trying to perform two operations say you're trying to add two tensors multiply two tensors or any kind of mathematical operations on two tensors both of them needs to need to be on the same device either CPU or GPU one of them on CPU and one of them in GPU this kind of case doesn't work right they have to be on the same tensor because like I explained a tensors computation like the way the workflow it goes through in the back end differs for CPU and GPU because GPU computation needs need to be faster. So CPU is capable of handling faster computation. So that's the case. So this is just an example showing I think a and B are on GPU and C is on CPU. So if I try to do a plus B if it's GPU tensor plus a GPU tensor and this is going to work if I try to do a plus C A is a GPU tensor and C is a CPU tensor. So this is the kind of error you get it expects all the tensors to be on the same device, but it finds at least two devices and that's not supported. Right? So like you can run this cell later on to compare again like I I pre-run this cell just before the recitation so that it will save us some time. So these are the times it took to so GPUs are generally faster is what we try to understand here. So this is just a simple example and to the main part training a neural network in PyTorch. So this is an example of how we can do this. We try to import all these apart from Torch you can we should import TorchVision and TorchVision transforms as well because these kind of transforms will be helpful, you know for us to you know, like norm for example, we can normalize the images or the input we have easily by just adding this line right earlier. It was more difficult, but now it's easier. So in these transforms generally we try to convert it to a tensor first and then normalize the tensor so you can add more kinds of transforms to this as well, you know, like horizontal flipping vertical vertical flipping of images and like yeah based on your application you can add but these are like the basic transform that most of the vision algorithms have converting to a PyTorch tensor and then normalizing the image. So as of now I've set the batch size to 4 and then here the TorchVision package already has a few common data set like MNIST, CIFAR-10 all these data sets are already present in the package and you can just import those like download those images. So the download will take a while. So I did it earlier. Yeah, so here you also have an option to set some of these parameters. If train is true, it's only going to download your train set in their CIFAR-10 data. If train is false. This is where it's going to download the test set, right? So once you download this data set, it's going to be of the type data set like yeah, it's going to be of the type data set and we want it to be a type data loader so that we can send it directly to a PyTorch trainer, right? So the differences in data set is going to be very specific to the kind of data you want like for example, whether it's a training data or a testing data or if you want to add some pre-processing to the image. All these things are handled by inside a data set itself inside a data set type. Okay, data set type and then in data loader what you can define is the batch size if you want to shuffle the data in each batch or not and the number of workers you're trying to use all the training related parameters can be set in the data loader. All the data specific parameters are set in the data set itself. Okay, so that's the difference. And finally we need a data loader type to actually start the PyTorch training process. So this is one thing and these are the different classes in the data. Yeah, and this is the example. This is the forward and in it I was talking about earlier as well. So this is the main nn.module which needs to be inherited for to define any kind of neural to define any kind of PyTorch function, sorry PyTorch architecture. So once you import inherit this nn.module you can write these functions init and forward in init. What all you need to do is define each of these layers say one convolution layer like I mentioned see you import torch.nn as nn and this torch itself is going to have predefined definitions for convolution 2D, match pool, convolution, linear. It has even activation functions like relu as well. See relu. So you just need to define all of these layers and then in forward based on the occurrence of each of these layers say you want your con1 layer first then you can call call con1 on x input first and then it's followed by a relu layer and then it's followed by a match pool layer. So based on your order of layers, you can just write these functions. It's a very simple thing of actually defining an architecture in PyTorch. So there are three parts in your to train a particular neural network in PyTorch. The first part is this which we already did, you know, defining a data set and a data loader. There is also an option to write a custom data set custom data loader. So in this case, we are just importing whatever we have in PyTorch in Torch region. So this is the first part. The second part is actually defining the your network architecture, right? This is a simple part. Generally, if you know, if you're writing a custom data set, this is going to be a complex part and then the architecture itself is relatively simpler to implement because based on your diagram of the your network architecture, you can just keep adding those layers in the same order. And the last step is going to be your actual training loop, right? For that we need a criterion is your loss function and optimizer is your, you know, like I don't know in this case, we are taking an SDD optimizer, like there are other optimizers as well. You must have heard in the lecture, Adam optimizer, SDD, etc. So we need these two things and also this is just a, you know, I think this is a overview that I told already. Okay. I think this is different. This is for the training loop. So for the training loop in any Torch model, so you'll have like in this example. Okay, let me first go through this one. So for each iteration, you need to remember to zero out the gradient and then perform a forward pass that we were doing earlier. Just the normal since we have this forward already once you call this forward and give it an input that itself is your forward pass. It is a single code, single line code. And then next you compute the loss. So you have this criterion defined already. So since you have this defined if you give your predicted variable, predicted y and your target y, this criterion itself will calculate the loss for you and return the value, right? That's also one line code and then a backward pass on loss to compute the gradient. We have seen already that on your final variable in if your input variables requires grad is true on your final variable, you can just call dot backward and it will back through the entire architecture for you. That's again a one line code, right? And then you have the optimizer step to update the parameters. We are going to see what this is later. We also have this optimizer defined. It's going to be an SDD optimizer. So we just need to activate it like, you know, ask it to make a step after every iteration, right? That's the step. So this is the actual these are the main steps for any training loop. I'll also show you the show you an example for but yeah, okay, and then for testing you need to set the model to eval more by calling net dot eval because generally your net needs to support back propagation etc. So it's definitely going to be in training mode in case you don't want to back drop and like you don't want them to link with each other. You need to make sure that you call net dot eval because it will change the model other way like it will mess up the model otherwise because yeah, you don't need to track the gradient and also don't have to back drop right? Proposed only in training you. Yeah, but you just make sure to do net dot eval before any kind of testing or validation. This is the general training loop. So I've set the memo box just to here. So for every epoch for each epoch all this stuff is going to happen. So first it is set to net dot train mode just in case it was it it was in an eval mode or some other mode. We need to make sure that it's in train mode, right? So yeah, this is just to make sure that if it's already in train mode, nothing is going to happen. If it's not in train mode, the network is set to a train mode and then you have a running loss of 0.0 and for IE data in train loader. So for in each epoch you need to go through the entire training data and do these steps, right? So the second loop is to go through the training data and the first loop is for to go through those many number of epochs. So here first you get your inputs and targets from the data. And then this was the first step, right? You zeroed all your gradients. Remember to zero the gradients. So this is the optimizer dot zero grad and then you do this because you don't have you don't want to have your previous iterations gradients in your network, right? You want to work with fresh gradients. So you zeroed all this gradient. So that's like when you back drop those are the fresh gradients that are being back propagated and you're not you know, accumulating the previous backdrops gradients. So this is the first step and then the second step was to perform a forward pass. So this is just this even if you do net dot inputs, it's similar to writing net dot forward of inputs. It's similar to this. Yeah, net of inputs is very is taken as similar to net dot forward and by dodge. So it's like calling this one, right? If you're calling net of an input, yeah, this will be called and you'll get the output of the forward propagation. Yeah, once you do the forward pass, you need to compute the loss based on these predicted values, right? So like I said, are you already have the criterion and you just send the predicted values followed by the target values and you get the last value here again. Like I said, all these are all these steps are just one line course. Yeah, if you see it individually, it's just a simple training loop. You just need to get used to it. I guess that's all and the next step is doing the last or backward. This is the back propagation step. It's just a simple one line small code. And then the last step is to do an optimizer dodge step like bringing in the SDD optimizer that we defined optimizing according to the rules of SDD. And then finally, are you accumulate the running loss by doing loss dot item just gives you the actual value of the loss instead of all the other baggage it carries. So yeah, so this is just going to be a floating value and we are trying to accumulate this loss for the entire data set, right? So that's where we define the running losses 0, 0 training data loop. So this is just to print the last value so that you understand whether the loss is decreasing or increasing. Since one whole epoch is taking going to take a long time. We just try to print it at every 2000 steps after every 2000 steps of this iteration like after after going through 2000 batches, I'm trying to print the loss. And then like yeah, making the running loss. So you can run this and this will take a while to finish to a part of the how it goes. Yeah, there is no error. I just interrupted it when it was running. Yeah, and then the final important thing is you just can't train the model and like once you train the model your net is going to have the network weight and you must have already observed in collab that your runtime gets disconnected. Right? Once you run time gets disconnected, you lost all your variables and all your training time will go in vain in case you don't save those network rates. Right? Yeah, so pytorch provides an option to save the network rates in a in a.pth file.